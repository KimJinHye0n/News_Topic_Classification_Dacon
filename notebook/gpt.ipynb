{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCEo-b2fPSnt",
        "outputId": "0cebee81-5f8e-4cb3-a4e1-34a48d96b358"
      },
      "source": [
        "!git clone https://github.com/kiyoungkim1/LMkor\n",
        "!pip3 install -q transformers\n",
        "\n",
        "from LMkor.examples.gpt3_generation import Inference"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'LMkor' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65fE5H3cZRFf"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertTokenizerFast, TFGPT2LMHeadModel, GPT2LMHeadModel\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "class Inference():\n",
        "    def __init__(self, model_name, tf_pt='tf'):\n",
        "        self.tf_pt = tf_pt\n",
        "\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "        if self.tf_pt == 'tf':\n",
        "            self.model = TFGPT2LMHeadModel.from_pretrained(model_name, pad_token_id=self.tokenizer.eos_token_id)\n",
        "        else:\n",
        "            self.model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=self.tokenizer.eos_token_id)\n",
        "\n",
        "    def __call__(self, text, howmany=3):\n",
        "        input_ids = self.tokenizer.encode(text, return_tensors='tf' if self.tf_pt=='tf' else 'pt')\n",
        "        input_ids = input_ids[:, 1:]  # remove cls token\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            input_ids,\n",
        "            min_length=30,\n",
        "            max_length=64,\n",
        "            do_sample=True,\n",
        "            top_k=10,\n",
        "            top_p=0.95,\n",
        "            no_repeat_ngram_size=2,\n",
        "            num_return_sequences=howmany\n",
        "        )\n",
        "        lists = []\n",
        "        for idx, generated in enumerate([self.tokenizer.decode(sentence, skip_special_tokens=True) for sentence in outputs]):\n",
        "            lists.append(generated[len(text):])\n",
        "        return lists[0]\n",
        "  \n",
        "inference = Inference('kykim/gpt3-kor-small_based_on_gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1-XST3sQYuD"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECejmzv7bHld"
      },
      "source": [
        "## TEXT_GPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp8ER20tRHBM",
        "outputId": "62884992-1e9f-4c01-aa12-7aa412722e46"
      },
      "source": [
        "df_it = df[df['topic_idx'] == 0]\n",
        "df_it.title = df_it.loc[:, \"title\"].apply(word_eda)\n",
        "df_it.reset_index(inplace=True)\n",
        "df_it = df_it[2170:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5VrofOISFfQ",
        "outputId": "0095e9f9-556e-4ef7-8333-be5855e123b7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "df_gpt = pd.DataFrame(columns=['title'])\n",
        "for i in tqdm(df_it.title) :\n",
        "  df_gpt = df_gpt.append({'title' : inference(i, howmany=1)}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2654/2654 [3:30:02<00:00,  4.75s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTz8jl61X_Dx"
      },
      "source": [
        "df_gpt.to_csv('/content/drive/MyDrive/gpt_it.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9cSqEpaPHam"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}